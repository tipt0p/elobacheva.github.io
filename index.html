<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ekaterina Lobacheva</title>
  
  <meta name="author" content="Ekaterina Lobacheva">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- Logo from https://openmoji.org/ -->
  <link rel="icon" type="image/png" href="data/cactus.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ekaterina Lobacheva</name>
              </p>
              <p>I'm a deep learning researcher mainly focusing on understanding the properties of neural network training, loss landscape, and generalization. I am also interested in ensemble methods, properties of training dynamics and object representations obtained in different training paradigms, such as self-supervised and transfer learning, and scaling laws for neural networks. Currently, I am an independent researcher collaborating with <a href="https://mila.quebec/en/">Mila</a> and  <a href="https://bayesgroup.ru/">Bayesian Methods Research Group</a>, working with <a href="https://nicolas.le-roux.name/">Nicolas Le Roux</a>, <a href="https://sites.google.com/view/irinarish/">Irina Rish</a>, and <a href="https://scholar.google.ca/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>.
              </p>
              <p>Previously, I received a Specialist degree (BSc + MSc) at <a href="https://www.msu.ru/en/">Lomonosov Moscow State University</a> and a PhD in computer science at <a href="https://cs.hse.ru/en/">HSE University</a> (advised by <a href="https://scholar.google.ca/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>).
              </p>
              <p style="text-align:center">
                <a href="mailto:lobacheva.tjulja@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/EkaterinaLobacheva-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.ru/citations?user=8D4Be1sAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/tipt0p">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/KateLobacheva">Twitter</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data/EkaterinaLobacheva.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="data/EkaterinaLobacheva.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				


        <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/transfer_ens_neurips23.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2303.03374">
          <papertitle>To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning</papertitle>
        </a>
        <br>
        <a href="https://www.linkedin.com/in/isadrtdinov/?originalSubdomain=ru">Ildus Sadrtdinov*</a>,
        <a href="https://dblp.org/pid/342/2878.html">Dmitrii Pozdeev*</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>,
        <strong>Ekaterina Lobacheva</strong>
        <br>
        <em>Neural Information Processing Systems (NeurIPS)</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2303.03374">paper</a>
        /
        <a href="https://openreview.net/forum?id=NNooZoQpP4">openreview</a>
        /
        <a href="https://nips.cc/virtual/2023/poster/71864">short poster video</a>
        /
        <a href="papers/transfer_ens_neurips23.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

          <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/large_lrs_ws23.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2311.11303">
          <papertitle>Large Learning Rates Improve Generalization: But How Large Are We Talking About?</papertitle>
        </a>
        <br>
        <strong>Ekaterina Lobacheva*</strong>,
        <a href="https://www.linkedin.com/in/celidos/">Eduard Pockonechnyy*</a>,
        <a href="https://scholar.google.com/citations?user=BGVWciMAAAAJ&hl=en">Maxim Kodryan</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>Mathematics of Modern Machine Learning Workshop at NeurIPS</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2311.11303">paper</a>
        /
        <a href="https://neurips.cc/virtual/2023/81682">poster</a>
        /
        <a href="papers/large_lrs_ws23.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/three_regimes_neurips22.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2209.03695">
          <papertitle>Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes</papertitle>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=BGVWciMAAAAJ&hl=en">Maxim Kodryan*</a>,
        <strong>Ekaterina Lobacheva*</strong>,
        <a href="https://www.linkedin.com/in/nakhodnov17/?originalSubdomain=ru">Maksim Nakhodnov*</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>Neural Information Processing Systems (NeurIPS)</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2209.03695">paper</a>
        /
        <a href="https://openreview.net/forum?id=edffTbw0Sws">openreview</a>
        /
        <a href="https://github.com/tipt0p/three_regimes_on_the_sphere">code</a>
        /
        <a href="https://nips.cc/virtual/2022/poster/53275">short poster video</a>
        /
        <a href="https://www.youtube.com/watch?v=ZCIa6HuawQY">long talk (in Russian)</a>
        /
        <a href="papers/three_regimes_neurips22.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/periodic_behavior_neurips21.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2106.15739">
          <papertitle>On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay</papertitle>
        </a>
        <br>
        <strong>Ekaterina Lobacheva*</strong>,
        <a href="https://scholar.google.com/citations?user=BGVWciMAAAAJ&hl=en">Maxim Kodryan*</a>,
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova</a>,
        <a href="https://scholar.google.com/citations?user=PnSFqO0AAAAJ&hl=en">Andrey Malinin</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>Neural Information Processing Systems (NeurIPS)</em>, 2021
        <br>
        <a href="https://arxiv.org/abs/2106.15739">paper</a>
        /
        <a href="https://openreview.net/forum?id=B6uDDaDoW4a">openreview</a>
        /
        <a href="https://github.com/tipt0p/periodic_behavior_bn_wd">code</a>
        /
        <a href="https://nips.cc/virtual/2021/poster/26875">short poster video</a>
        /
        <a href="https://media.mis.mpg.de/mml/2021-12-02/">long talk</a>
        /
        <a href="papers/periodic_behavior_neurips21.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/memorization_contrastive_ws21.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2107.10143">
          <papertitle>On the Memorization Properties of Contrastive Learning</papertitle>
        </a>
        <br>
        <a href="https://www.linkedin.com/in/isadrtdinov/?originalSubdomain=ru">Ildus Sadrtdinov</a>,
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova</a>,
        <strong>Ekaterina Lobacheva</strong>
        <br>
        <em>Workshop on Overparameterization: Pitfalls & Opportunities at ICML</em>, 2021
        <br>
        <a href="https://arxiv.org/abs/2107.10143">paper</a>
        /
        <a href="papers/memorization_contrastive_ws21.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

         <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/power_laws_de_neurips20.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2007.08483">
          <papertitle>On Power Laws in Deep Ensembles</papertitle>
        </a>
        <br>
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova</a>,
        <a href="https://scholar.google.com/citations?user=BGVWciMAAAAJ&hl=en">Maxim Kodryan</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>Neural Information Processing Systems (NeurIPS)</em>, 2020 &nbsp <font color="red"><strong>(Spotlight)</strong></font>
        <br>
        <em>Workshop on Uncertainty and Robustness in Deep Learning at ICML</em>, 2020
        <br>
        <a href="https://arxiv.org/abs/2007.08483">paper</a>
        /
        <a href="https://proceedings.neurips.cc/paper/2020/hash/191595dc11b4d6e54f01504e3aa92f96-Abstract.html">reviews</a>
        /
        <a href="https://github.com/tipt0p/power_laws_deep_ensembles">code</a>
        /
        <a href="https://nips.cc/virtual/2020/public/poster_191595dc11b4d6e54f01504e3aa92f96.html">short poster video</a>
        /
        <a href="https://www.youtube.com/watch?v=lPku_0tq0Ho&t=3500s">long talk (in Russian)</a>
        /
        <a href="papers/power_laws_de_neurips20.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

        <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/memory_budget_arxiv20.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2005.07292">
          <papertitle>Deep Ensembles on a Fixed Memory Budget: One Wide Network or Several Thinner Ones?</papertitle>
        </a>
        <br>
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova</a>,
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>arXiv preprint</em>, 2020
        <br>
        <a href="https://arxiv.org/abs/2005.07292">paper</a>
        /
        <a href="papers/memory_budget_arxiv20.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

        <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/structured_sparsification_aaai20.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5938">
          <papertitle>Structured Sparsification of Gated Recurrent Neural Networks</papertitle>
        </a>
        <br>
        <strong>Ekaterina Lobacheva*</strong>,
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova*</a>,
        <a href="https://scholar.google.com/citations?user=Ug61YgMAAAAJ&hl=en">Alexander Markovich</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>AAAI Conference on Artificial Intelligence</em>, 2020 &nbsp <font color="red"><strong>(Oral)</strong></font>
        <br>
        <em>Workshop on Context and Compositionality in Biological and Artificial NSs at NeurIPS</em>, 2019
        <br>
        <em>Workshop on Compact Deep Neural Networks with Industrial Applications at NeurIPS</em>, 2018
        <br>
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5938">paper</a>
        /
        <a href="https://github.com/tipt0p/SparseGatedRNN">code</a>
        /
        <a href="papers/structured_sparsification_aaai20.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

         <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/bayesian_compression_emnlp18.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/1810.10927">
          <papertitle>Bayesian Compression for Natural Language Processing</papertitle>
        </a>
        <br>
        <a href="https://nadiinchi.github.io/">Nadezhda Chirkova*</a>,
        <strong>Ekaterina Lobacheva*</strong>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2018
        <br>
        <em>Workshop on Learning to Generate Natural Language at ICML</em>, 2017
        <br>

        <a href="https://arxiv.org/abs/1810.10927">paper</a>
        /
        <a href="https://github.com/tipt0p/SparseBayesianRNN">code</a>
        /
        <a href="papers/bayesian_compression_emnlp18.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

        <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/adaptive_time_arxiv18.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/pdf?id=SkIr6FywG">
          <papertitle>Adaptive prediction time for sequence classification</papertitle>
        </a>
        <br>
        <a href="https://mryab.github.io/">Maksim Ryabinin</a>,
        <strong>Ekaterina Lobacheva</strong>
        <br>
        <em>preprint</em>, 2018
        <br>
        <a href="https://openreview.net/pdf?id=SkIr6FywG">paper</a>
        /
        <a href="https://openreview.net/forum?id=SkIr6FywG">openreview</a>
        /
        <a href="papers/adaptive_time_arxiv18.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/monotonic_ws18.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/1804.03643">
          <papertitle>Monotonic models for real-time dynamic malware detection</papertitle>
        </a>
        <br>
        <a href="https://www.linkedin.com/in/alexander-chistyakov/">Alexander Chistyakov</a>,
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://www.linkedin.com/in/alshev/?originalSubdomain=ru">Alexander Shevelev</a>,
        <a href="https://dblp.org/pid/17/7422.html">Alexey Romanenko</a>,
        <br>
        <em>ICLR Workshop</em>, 2018
        <br>
        <a href="https://arxiv.org/abs/1804.03643">paper</a>
        /
        <a href="https://openreview.net/forum?id=rkjatuyvM">openreview</a>
        /
        <a href="papers/monotonic_ws18.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

            <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/program_emb_ws17.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/1804.03635">
          <papertitle>Semantic embeddings for program behavior</papertitle>
        </a>
        <br>
        Alexander Chistyakov, Ekaterina Lobacheva, Arseny Kuznetsov, Alexey Romanenko
        <a href="https://www.linkedin.com/in/alexander-chistyakov/">Alexander Chistyakov</a>,
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://scholar.google.com/citations?user=5ir1F_cAAAAJ&hl=ru">Arseny Kuznetsov</a>,
        <a href="https://dblp.org/pid/17/7422.html">Alexey Romanenko</a>,
        <br>
        <em>ICLR Workshop</em>, 2017
        <br>
        <a href="https://arxiv.org/abs/1804.03635">paper</a>
        /
        <a href="https://openreview.net/forum?id=BJ_X2yHFe">openreview</a>
        /
        <a href="papers/program_emb_ws17.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/shape_model_bmvc16.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="http://www.bmva.org/bmvc/2016/papers/paper088/paper088.pdf">
          <papertitle>Deep Part-Based Generative Shape Model with Latent Variables</papertitle>
        </a>
        <br>
        <a href="https://alexander-kirillov.github.io/">Alexander Kirillov</a>,
        <a href="https://dblp.org/pid/198/2585.html">Mikhail Gavrikov</a>,
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://aosokin.github.io/">Anton Osokin</a>,
        <a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Dmitry Vetrov</a>
        <br>
        <em>British Machine Vision Conference (BMVC)</em>, 2016
        <br>
        <a href="http://www.bmva.org/bmvc/2016/papers/paper088/paper088.pdf">paper</a>
        /
        <a href="papers/shape_model_bmvc16.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

        <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src='images/joint_segm_clust_iccv15.png' width="160px">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Lobacheva_Joint_Optimization_of_ICCV_2015_paper.pdf">
          <papertitle>Joint Optimization of Segmentation and Color Clustering</papertitle>
        </a>
        <br>
        <strong>Ekaterina Lobacheva</strong>,
        <a href="https://scholar.google.com/citations?user=r5QkMysAAAAJ&hl=en">Olga Veksler</a>,
        <a href="https://scholar.google.com/citations?user=h6_PdYsAAAAJ&hl=en">Yuri Boykov</a>
        <br>
        <em>International Conference on Computer Vision (ICCV)</em>, 2015
        <br>
        <a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Lobacheva_Joint_Optimization_of_ICCV_2015_paper.pdf">paper</a>
        /
        <a href="papers/joint_segm_clust_iccv15.txt">bibtex</a>
        <p></p>
      </td>
    </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The webpage template was borrowed from <a href="https://people.eecs.berkeley.edu/~barron/">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
